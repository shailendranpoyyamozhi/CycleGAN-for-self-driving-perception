# CycleGAN-for-self-driving-perception
Perception operation in autonomous systems enables sensing environments around the system.
This is crucial to make decisions, plan, and operate in real-world environments through numerous
functionalities and operations from occupancy maps to object detection. To perform these essential
operations, autonomous systems use a variety of sensors, namely RADAR, LiDAR, GPS, Camera,
etc. Each sensor has its functionality, such as, to name a few, for path planning, GPS, for distance
tracking/object detection RADAR/Lidar, for lane-keeping the Camera, etc., are used. These sensors
are not responsive in adverse weather. Camera is the only sensor, which has the ability to view the
environment. The main objective of present autonomous vehicle development is to use as few sensors
as possible to perform perception operations without compromising safety. In this paper, we present
an AI-based method named cycle-GAN to clear the adverse weather condition, which will help us
perform various perception operations.
## CycleGAN structure
![](https://github.com/shailendranpoyyamozhi/CycleGAN-for-self-driving-perception/blob/main/images/cyclegan.jpg)
## Output of cycleGAN
![](https://github.com/shailendranpoyyamozhi/CycleGAN-for-self-driving-perception/blob/main/images/Output.jpg)
